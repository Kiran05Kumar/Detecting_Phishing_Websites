{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f86329-e1b6-4a0e-8c96-6d9cb560e29c",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af46bc3b-9493-4998-bf9d-bc4d8b009714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebf24a-2941-41eb-9625-f723b06fd43d",
   "metadata": {},
   "source": [
    "# URL Based\n",
    "\"URL-based\" typically refers to operations, processes, or functionality that specifically work with Uniform Resource Locators (URLs), which are the web addresses used to identify resources on the internet. When you work with URLs in your code, you are often performing tasks like parsing, validating, extracting, or manipulating parts of the URL (e.g., protocol, host, path, query parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaff4d3d-3707-44ff-8ab8-930c22029521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing urlparse module from urllib\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Importing the regular expression module\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6b301-11bf-4e98-8376-e7847e8f5eaf",
   "metadata": {},
   "source": [
    "### Checking IP\n",
    "checks if a given URL contains an IP address and assigns a value based on whether the URL is malicious or legitimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5094d0eb-5ec1-45d6-bdac-d8412c7ea356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "\n",
    "# Function to check if the URL contains an IP address\n",
    "def havingIP(url):\n",
    "    try:\n",
    "        # Try to convert the URL to an IP address using the ip_address function\n",
    "        ipaddress.ip_address(url)\n",
    "        ip = 1  # If it is a valid IP address, return 1 (malicious)\n",
    "    except:\n",
    "        ip = 0  # If it's not a valid IP address, return 0 (legitimate)\n",
    "    return ip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0c366-5f7c-4338-a7ee-86d59ccfd1a3",
   "metadata": {},
   "source": [
    "### Checking @\n",
    "haveAt() checks whether the provided URL contains the \"@\" symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a57086b-b5d6-4bb9-8ec8-93ccb94363e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the URL contains the \"@\" symbol\n",
    "def haveAt(url):\n",
    "    if \"@\" in url:  # If \"@\" symbol is found in the URL\n",
    "        return 1  # Malicious URL (contains \"@\")\n",
    "    else:\n",
    "        return 0  # Legitimate URL (no \"@\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb864315-7637-4d41-9e21-9b3aa5ac4816",
   "metadata": {},
   "source": [
    "### Finding URL Lenght\n",
    "url_length() checks the length of a given URL and assigns a value based on whether the URL length is greater than 55 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44783f3-477c-4bef-aadf-0d9df0b236ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the URL length is greater than 55 characters\n",
    "def url_length(url):\n",
    "    if len(url) > 55:  # If the length of the URL is greater than 55 characters\n",
    "        return 1  # Malicious (long URL)\n",
    "    else:\n",
    "        return 0  # Legitimate (short URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456bda1-2caa-4c08-be3b-af231cfe33ba",
   "metadata": {},
   "source": [
    "### Finding URL Depth\n",
    "url_depth() is designed to check the \"depth\" of a URL based on how many slashes (/) are present in the URL's path. This can be used to indicate how deeply nested a URL is, which can sometimes be a feature of malicious URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597ae005-0f0b-4526-85a9-ebdc9e1f003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the URL depth (count of slashes in the path)\n",
    "def url_depth(url):\n",
    "    parsed_url = urlparse(url)  # Parse the URL into its components\n",
    "    path = parsed_url.path  # Extract the path component of the URL\n",
    "    depth = path.count('/')  # Count the number of slashes in the path to determine depth\n",
    "    return depth  # Return the depth of the URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03595dc3-89e6-4c8e-a30b-6f0234cd53e8",
   "metadata": {},
   "source": [
    "### Checking Redirects\n",
    "The Redirection() function you provided checks whether a URL contains a potential redirection (i.e., if the URL has // at positions that suggest a redirection might be taking place). The function appears to be trying to detect URLs that may involve redirects by checking the position of the // sequence in the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ffcc54-dc07-409c-9143-659ca73ba062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redirection(url):\n",
    "    loc = url.rfind('//')  # Find the last occurrence of \"//\" in the URL\n",
    "    if loc > 6:  # Check if \"//\" appears after the 6th character\n",
    "        if loc > 7:  # If \"//\" occurs after the 7th character\n",
    "            return 1  # Potential redirection (malicious)\n",
    "        else:\n",
    "            return 0  # No redirection (legitimate)\n",
    "    else:\n",
    "        return 0  # No redirection (legitimate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a553a1-13b8-4eb6-a921-ed49cc1771b7",
   "metadata": {},
   "source": [
    "### Checking for HTTP and HTPPS\n",
    "The https_domain() function you provided aims to check if a URL's domain contains the string https, indicating whether the URL is using HTTPS or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163c7916-88d2-4084-bef3-b9f296d198e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def https_domain(url):\n",
    "    domain = urlparse(url).netloc  # Extract the domain part of the URL\n",
    "    if 'https' in domain:  # Check if 'https' appears in the domain (which is not correct for HTTPS checking)\n",
    "        return 1  # Malicious URL\n",
    "    else:\n",
    "        return 0  # Legitimate URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b224cff-6a74-49fe-857a-7dae5534fbc8",
   "metadata": {},
   "source": [
    "### Checking for URL Shorteners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e656283a-4cbb-4c96-8dcc-e2b22bf2a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking if the URL used link shorteners.\n",
    "# If the URL has used link shortener it is assigned with 1 and 0 if it didn't use.\n",
    "# 1 indicating that the URL is malacious whereas 0 indicating legitimate URL.\n",
    "\n",
    "def TinyUrl(url):\n",
    "    shortener_domains = ['bit.ly','goo.gl','t.co','ow.ly', 'tinyurl.com','is.gd', 'buff.ly',\n",
    "    'adobe.ly','shorturl.at','tiny.cc','ow.ly',\n",
    "    's.coop','rebrand.ly','soo.gd','v.gd','prettylinks.com','bc.vc',\n",
    "    'cutt.ly','qr.ae','u.nu','shorl.com',\n",
    "    'mcaf.ee','tr.im','fur.ly','cli.gs','yourls.org','tiny.pl','vzturl.com','adcrun.ch','x.co','zz.gd',\n",
    "    'qr.net','tr.im','shorte.st','9.bb','ity.im','adf.ly','flyt.it','lin.ks','adflav.com','amzn.to',\n",
    "    '0rz.tw','crisco.com','snipurl.com','memurl.com','dft.ba','clicky.me','7.ly',\n",
    "    'budurl.com','u.to','pnt.me','viralurl.com','2.gp','xlinkz.info','3.ly',\n",
    "    '9.bb','10.go','ergo.pp.ua','golinks.co','tiny.ie','adcraft.co','sk.gy',\n",
    "    'xzb.cc','lin.io','go.9nl.com','u.bb','hiderefer.com','tu2.ru','x.vu','lnk.co',\n",
    "    'su.pr','shar.as','notlong.com','zpag.es','u6e.de','2ya.com','viralurl.biz','4ms.me',\n",
    "    'rofl.my','lurl.no','url.ie','ff.im','hit.my','korta.nu','x.se','ref.so','durl.me',\n",
    "    'fwib.net','zii.bz','vzturl.com','memurl.com','dft.ba','1url.com','tinylinks.co','vb.ly',\n",
    "    'qr.cx','go.2link.me','tweetburner.com','pic.gd','2u.pw','ls.gd','2pl.us',\n",
    "    'urlx.ie','utrack.me','yi.tl','ref.li','zipmyurl.com','qicute.com','cx6.co','x90.es','urlcorta.es',\n",
    "    'pw2.ro','cort.as','minilien.com','yourls.com','hurl.me','tgr.me','shout.to',\n",
    "    'x2c.eu','shrten.com','dwarfurl.com','lnkd.in','dai.ly','v.gd','nyti.ms','aje.me',\n",
    "    'huff.to','slate.me','trib.al','pco.lt','thetim.es','n.pr','reut.rs','on.wsj.com','usat.ly','nbcnews.to',\n",
    "    'abcn.ws','cbsn.ws','tcrn.ch','engt.co','bzfd.it','bzfd.it','ti.me','bzfd.it','natgeo.org',\n",
    "    'ars.to','ti.me','bzfd.it','natgeo.org','ars.to','bzfd.it','for.tn','bzfd.it','t.ted.com',\n",
    "    'hbr.org','slate.me','bzfd.it','bzfd.it','for.tn','bzfd.it','huffp.st','bzfd.it','nyti.ms','slate.me',\n",
    "]\n",
    "    domain = urlparse(url).netloc  # Extract the domain part of the URL\n",
    "    \n",
    "    # Check if any of the shortener domains are in the URL's domain\n",
    "    for shortener in shortener_domains:\n",
    "        if shortener in domain:\n",
    "            return 1  # Malicious URL\n",
    "    return 0  # Legitimate URL if no shortener domain found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52bcc19-0f44-4850-8559-dba75918d61b",
   "metadata": {},
   "source": [
    "### Checking Prefix and Suffix\n",
    "The PSFix() function you've written checks whether the domain part of the URL contains a hyphen (-). If it does, the function returns 1, indicating that the URL might be suspicious (malicious). Otherwise, it returns 0, indicating that the URL is legitimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9de5a9c-a1a4-4c51-bf9e-cbe4fdf07da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSFix(url):\n",
    "    # Extract the domain (netloc) from the URL\n",
    "    fix = urlparse(url).netloc\n",
    "\n",
    "    # Check if a hyphen ('-') is present in the domain part of the URL\n",
    "    if '-' in fix:\n",
    "        return 1  # Potentially malicious, as many phishing sites use hyphens in the domain\n",
    "    else:\n",
    "        return 0  # No hyphen, likely a legitimate URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e24c4e1-e977-4455-84ff-3f17b02ccdd7",
   "metadata": {},
   "source": [
    "# HTML and JavaScript based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de1732dd-46b3-4746-8032-fb2c97e9f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The requests module is a popular Python library used for making HTTP requests. It simplifies the process of sending HTTP requests and handling responses, making it easier to interact with web APIs and web scraping tasks\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562824f-be3a-4bbb-8e23-00ff4653d6a9",
   "metadata": {},
   "source": [
    "### iFrame Redirections \n",
    "The function iFrame(response) is designed to check the response from a web request to determine if an iframe is present within the HTML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018731f9-3904-4300-a282-37f25ae73418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iFrame(response):\n",
    "    # Check if response is empty\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        # Look for <iframe> tags in the HTML content\n",
    "        if re.findall(r\"<iframe.*?>\", response.text):\n",
    "            return 0  # Indicates possible malicious content with iframe\n",
    "        else:\n",
    "            return 1  # No iframe found, likely legitimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3273589-a0b3-4476-a1cc-77f49b3dbcba",
   "metadata": {},
   "source": [
    "### Mouse Over\n",
    "The function Mouse_Over(response) seems to be attempting to check for some specific content in a webpage's HTML that might indicate a \"mouseover\" event, which typically involves a user interacting with an element on the page by hovering the mouse over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8adb14fb-9a0c-4b6a-85c2-c80352e3ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mouse_Over(response):\n",
    "    if response == \"\":\n",
    "        return 1  # Returning 1 for empty response\n",
    "    \n",
    "    # Looking for the presence of the 'onmouseover' attribute in the HTML content\n",
    "    elif re.findall(r'onmouseover=\".*?\"', response.text):  # Search for mouseover events\n",
    "        return 1  # Indicates possible malicious content or interactive behavior\n",
    "    else:\n",
    "        return 0  # No mouseover events, likely legitimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851d6a9-835b-4bf8-81e2-112a53b891ae",
   "metadata": {},
   "source": [
    "### Right Click\n",
    "The Right_Click function you're implementing appears to be attempting to detect the presence of JavaScript code that prevents right-clicking (which is a common tactic used in phishing or malicious websites to restrict user actions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee054ea3-49d3-4065-bc21-1e88e003004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Right_Click(response):\n",
    "    if not response:  # Check if the response is empty\n",
    "        return 1  # Return 1 for empty response\n",
    "    else:\n",
    "        # Check if the page contains the pattern indicating right-click is disabled\n",
    "        if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "            return 0  # Return 0 if right-click is disabled\n",
    "        else:\n",
    "            return 1  # Return 1 if right-click is enabled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ecc604-8bf9-480f-a670-d25f904815cb",
   "metadata": {},
   "source": [
    "### Web Forwards\n",
    "The Web_Forwards function you’ve defined is likely trying to check if a URL undergoes multiple redirects, which could be a characteristic of phishing or malicious websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2be99662-59cb-4407-9e5b-bbbc39547b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Web_Forwards(url):\n",
    "    if not url or not url.startswith(('http://', 'https://')):\n",
    "        print(f\"Invalid URL: {url}\")\n",
    "        return 0  # Return a default value or handle accordingly\n",
    "    \n",
    "    # Send a GET request to the URL and follow redirects\n",
    "    try:\n",
    "        response = requests.get(url, allow_redirects=True)\n",
    "        # Check if the response has a redirect history\n",
    "        if len(response.history) <= 2:  # Less than or equal to 2 redirects\n",
    "            return 0  # No suspicious redirects\n",
    "        else:\n",
    "            return 1  # Suspicious redirects\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return 0  # Return a default value if the request fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ea74b-5fff-4ae7-8e5a-ab19fee86306",
   "metadata": {},
   "source": [
    "# Input Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22694bd8-9b94-4a30-a303-9686c6dbcbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the URL that needs to be evaluated:  https://mail.google.com/mail/u/0/?tab=rm&ogbl#inbox/FMfcgzGsnBmKbNRFtQfMbdBqFhQFhgSF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing URL: https://mail.google.com/mail/u/0/?tab=rm&ogbl#inbox/FMfcgzGsnBmKbNRFtQfMbdBqFhQFhgSF\n",
      "\n",
      "Extracted Features:\n",
      "IP Address: 0\n",
      "At Symbol: 0\n",
      "URL Length: 1\n",
      "URL Depth: 0\n",
      "Redirection: 0\n",
      "HTTPS in Domain: 0\n",
      "TinyURL: 0\n",
      "Suspicious Fix: 0\n",
      "iFrame: 0\n",
      "Mouse Over: 0\n",
      "Right Click Disabled: 1\n",
      "Web Forwards: 1\n",
      "\n",
      "Result: ✅ Legitimate (56.98% confidence)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def validate_url(url):\n",
    "    \"\"\"Clean and validate URL input\"\"\"\n",
    "    # Remove any leading/trailing whitespace and 'Enter the url...' text\n",
    "    url = url.strip()\n",
    "    if \"Enter the url\" in url:\n",
    "        url = url.split(\":-\")[-1].strip()\n",
    "    \n",
    "    parsed_url = urlparse(url)\n",
    "    if not parsed_url.scheme:\n",
    "        url = \"https://\" + url  # Use HTTPS as default scheme\n",
    "    return url\n",
    "\n",
    "def havingIP(url):\n",
    "    \"\"\"Check if URL contains IP address\"\"\"\n",
    "    ip_pattern = r'(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)'\n",
    "    return 1 if re.search(ip_pattern, url) else 0\n",
    "\n",
    "def haveAt(url):\n",
    "    \"\"\"Check if URL contains @ symbol\"\"\"\n",
    "    return 1 if '@' in url else 0\n",
    "\n",
    "def url_length(url):\n",
    "    \"\"\"Check if URL length is suspicious\"\"\"\n",
    "    return 1 if len(url) > 75 else 0\n",
    "\n",
    "def url_depth(url):\n",
    "    \"\"\"Calculate URL directory depth\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    depth = parsed.path.count('/')\n",
    "    return 1 if depth > 4 else 0\n",
    "\n",
    "def Redirection(url):\n",
    "    \"\"\"Check for redirections in URL\"\"\"\n",
    "    return 1 if '//' in url[8:] else 0\n",
    "\n",
    "def https_domain(url):\n",
    "    \"\"\"Check HTTPS in domain part\"\"\"\n",
    "    domain = urlparse(url).netloc\n",
    "    return 1 if 'https' in domain else 0\n",
    "\n",
    "def TinyUrl(url):\n",
    "    \"\"\"Check if URL is using a URL shortening service\"\"\"\n",
    "    shortening_services = ['bit.ly', 'tinyurl.com', 'goo.gl', 't.co']\n",
    "    return 1 if any(service in url.lower() for service in shortening_services) else 0\n",
    "\n",
    "def PSFix(url):\n",
    "    \"\"\"Check for suspicious prefixes/suffixes\"\"\"\n",
    "    suspicious = ['-', '.', '_']\n",
    "    domain = urlparse(url).netloc\n",
    "    return 1 if any(domain.startswith(c) or domain.endswith(c) for c in suspicious) else 0\n",
    "\n",
    "def iFrame(response):\n",
    "    \"\"\"Check for iframes in response\"\"\"\n",
    "    try:\n",
    "        if isinstance(response, requests.models.Response):\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            return 1 if soup.find_all('iframe') else 0\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def Mouse_Over(response):\n",
    "    \"\"\"Check for mouseover events that modify status bar\"\"\"\n",
    "    try:\n",
    "        if isinstance(response, requests.models.Response):\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            onmouseover_events = soup.find_all(attrs={\"onmouseover\": True})\n",
    "            return 1 if any('window.status' in str(event) for event in onmouseover_events) else 0\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def Right_Click(response):\n",
    "    \"\"\"Check if right click is disabled\"\"\"\n",
    "    try:\n",
    "        if isinstance(response, requests.models.Response):\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            scripts = soup.find_all('script')\n",
    "            return 1 if any('preventDefault()' in str(script) or 'return false' in str(script) for script in scripts) else 0\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def Web_Forwards(url):\n",
    "    \"\"\"Check number of redirects\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, allow_redirects=True)\n",
    "        return 1 if len(response.history) > 1 else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def evaluate_url(url):\n",
    "    \"\"\"Main function to evaluate URL\"\"\"\n",
    "    # Clean and validate URL\n",
    "    url = validate_url(url)\n",
    "    print(f\"Analyzing URL: {url}\")\n",
    "    \n",
    "    # Extract features\n",
    "    feature = []\n",
    "    \n",
    "    # URL-based features\n",
    "    feature.append(havingIP(url))\n",
    "    feature.append(haveAt(url))\n",
    "    feature.append(url_length(url))\n",
    "    feature.append(url_depth(url))\n",
    "    feature.append(Redirection(url))\n",
    "    feature.append(https_domain(url))\n",
    "    feature.append(TinyUrl(url))\n",
    "    feature.append(PSFix(url))\n",
    "    \n",
    "    # Content-based features\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5, verify=True)\n",
    "        feature.append(iFrame(response))\n",
    "        feature.append(Mouse_Over(response))\n",
    "        feature.append(Right_Click(response))\n",
    "        feature.append(Web_Forwards(url))\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Couldn't fetch URL content ({str(e)})\")\n",
    "        feature.extend([0, 0, 0, 0])  # Add default values for content-based features\n",
    "    \n",
    "    # Print extracted features with labels\n",
    "    feature_names = ['IP Address', 'At Symbol', 'URL Length', 'URL Depth', \n",
    "                    'Redirection', 'HTTPS in Domain', 'TinyURL', 'Suspicious Fix',\n",
    "                    'iFrame', 'Mouse Over', 'Right Click Disabled', 'Web Forwards']\n",
    "    \n",
    "    print(\"\\nExtracted Features:\")\n",
    "    for name, value in zip(feature_names, feature):\n",
    "        print(f\"{name}: {value}\")\n",
    "    \n",
    "    # Make prediction\n",
    "    feature_array = np.array(feature).reshape(1, -1)\n",
    "    with open('random_forest_model.pkl', 'rb') as file:\n",
    "        rf_model = pickle.load(file)\n",
    "    \n",
    "    prediction = rf_model.predict(feature_array)[0]\n",
    "    probability = rf_model.predict_proba(feature_array)[0]\n",
    "    \n",
    "    return prediction, probability, feature\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = input('Enter the URL that needs to be evaluated: ')\n",
    "    prediction, probability, features = evaluate_url(url)\n",
    "    \n",
    "    if prediction == 1:\n",
    "        print(f\"\\nResult: ⚠️ Potential Phishing ({probability[1]:.2%} confidence)\")\n",
    "    else:\n",
    "        print(f\"\\nResult: ✅ Legitimate ({probability[0]:.2%} confidence)\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c9748-2646-4cb1-b83b-5a7a998ea848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
